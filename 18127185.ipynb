{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đồ án 4: Xử lí ngôn ngữ tự nhiên / Mô hình hồi quy tối tiểu"
   ]
  },
  {
   "source": [
    "## Thông tin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- **Họ và tên:** Bùi Vũ Hiếu Phụng\n",
    "- **MSSV:** 18127185\n",
    "- **Lớp:** Toán ứng dụng và Thống kê - MTH00051 @ 18CLC4\n",
    "- **Github:** [@alecmatts](https://github.com/alecmatts)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE this part: import libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu dạng văn bản"
   ]
  },
  {
   "source": [
    "- **Khởi tạo các global object cần thiết cho việc tiền xử lí**. Bao gồm:\n",
    "    - vocab: Bộ từ điển của chương trình, bao gồm các từ mới xuất hiện trong quá trình training. Ở đây được khởi tạo là một `list`.\n",
    "    - stemmer: Cổng stem để biến đổi một từ về từ gốc (root form), đưa các biến thể của từ về một từ duy nhất. Khởi tạo bằng object `nltk.stem.PorterStemmer` được khai báo ở phần import.\n",
    "    - stopwords: Bộ những từ phổ biến nhưng thừa thãi, không liên quan đến ngữ nghĩa của văn bản. Các từ này dễ gây nhiễu data, cản trở việc xử lí/phân loại văn bản nên cần được lược bỏ. Để lấy các từ này, ta dùng `nltk.corpus.stopwords`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "stemmer = PorterStemmer()\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "source": [
    "- **Xử lí chuỗi số (Chuyển các chuỗi số thành 'num')**\n",
    "    - Ban đầu em sử dụng RegEx để xác định các chuỗi số (Reference: [link](https://stackoverflow.com/questions/2811031/decimal-or-numeric-values-in-regular-expression-validation)) nhưng không thu được kết quả như mong đợi vì thiếu kiến thức về RegEx cũng như có nhiều trường hợp không thể bao quát hết được.\n",
    "    - Dưới đây, em chọn ép kiểu và `try/except` để xác định các chuỗi số, dễ đọc và dễ tiếp cận hơn. (Reference: [link](https://stackoverflow.com/questions/1265665/how-can-i-check-if-a-string-represents-an-int-without-using-try-except/1267145#1267145)). Dùng `try/except` để kiểm tra việc ép kiểu có hợp lệ không. Nếu:\n",
    "        - Có thể ép kiểu mà không báo lỗi thì chuỗi đó là số nguyên/thực. Ta trả về 'num'.\n",
    "        - Các trường hợp khác sẽ trả về chuỗi đó mà không có thay đổi gì."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numify(string):\n",
    "    # Khởi tạo biến để kiểm tra chuỗi số học hay không\n",
    "    isNumeric = False\n",
    "\n",
    "    # Kiểm tra tính hợp lệ của việc ép kiểu để xác định chuỗi số \n",
    "    try:\n",
    "        int(string) # Số nguyên\n",
    "        isNumeric = True\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        float(string) # Số thực\n",
    "        isNumeric = True\n",
    "    except ValueError: \n",
    "        pass\n",
    "    \n",
    "    # Các trường hợp trả về\n",
    "    return 'num' if isNumeric else string"
   ]
  },
  {
   "source": [
    "- **Tiền xử lí văn bản.**\n",
    "    - Ở đây cần phải đọc 2 bộ dữ liệu: train và valid/test. Nên có thêm một tham số đầu vào `train` nhận giá trị `True/False` để xác định loại dữ liệu.\n",
    "    - Bao gồm các công việc chung sau:\n",
    "        - Chuyển tất cả thành chữ thường. Dùng phương thức `string.lower()` của `python`.\n",
    "        - Tách từ. Dùng `nltk.tokenize.word_tokenize` từ thư viện `nltk` hỗ trợ cho việc xử lí ngôn ngữ tự nhiên.\n",
    "        - Loại bỏ stopwords. Duyệt qua từng phần từ của list từ bằng list comprehension, giữ lại các từ không thuộc `stopword`.\n",
    "        - Chuyển thành từ gốc. Dùng cổng `stemmer` đã khởi tạo ở đầu chương trình.\n",
    "        - Chuyển số thành 'num'. Sử dụng hàm `numify` đã cài đặt ở trên\n",
    "        - Đối với từng loại dữ liệu: Tương tác với `list` bình thường (dùng `append`)\n",
    "            - Bộ train: Thêm từ vào kết quả tiền xử lí của văn bản và thêm từ mới vào bộ từ điển của chương trình\n",
    "            - Bộ test: Thêm từ tồn tại trong bộ từ điển vào kết quả tiền xử lí của văn bản. Các từ chưa từng xuất hiện trong quá trình học sẽ được chuyển thành chuỗi 'unk'  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, train):\n",
    "    # Chuyển tất cả thành chữ thường\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tách từ thành list\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Loại bỏ stopwords\n",
    "    tokens = [t for t in tokens if not t in stopwords]\n",
    "\n",
    "    # Thêm từ vào kết quả tiền xử lí\n",
    "    result = []\n",
    "    for word in tokens:        \n",
    "        word = stemmer.stem(word) # Chuyển thành từ gốc\n",
    "        word = numify(word)       # Chuyển số thành 'num'\n",
    "\n",
    "        # Các điều kiện và hành vi với từng loại dữ liệu\n",
    "        if train:\n",
    "            result.append(word)\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "        else:\n",
    "            if word not in vocab:\n",
    "                result.append('unk')\n",
    "            else:\n",
    "                result.append(word)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "source": [
    "- **Đọc dữ liệu từ đường dẫn đến file**\n",
    "    - Mở và đọc file bằng `open()` và `json.load()`. Ta chỉ phân tích đánh giá và số điểm mà người dùng đưa ra nên ta chỉ cần quan tâm đến hai trường dữ liệu: `reviewText` và `overall` - trích xuất bằng cú pháp `<khối dữ liệu>['<trường dữ liệu>']` \n",
    "    - Phần văn bản lưu kết quả tiền xử lí của văn bản thông qua chạy hàm `preprocess` đã cài ở trên. Phần điểm (còn được coi là nhãn của văn bản) là một `np.array` chứa các số tương đương với số điểm mà người dùng chấm.\n",
    "    - Lưu chúng ở hai `list` khác nhau nhưng dễ dàng truy xuất đồng thời thông qua `index`. VD: ở index `i` ta có kết quả tiền xử lí của văn bản thứ `i` và nhãn của văn bản thứ `i`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path, train):\n",
    "    # Mở và đọc file\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Lưu kết quả tiền xử lí và nhãn văn bản như đã nói ở trên\n",
    "    pp_documents = []\n",
    "    labels = []\n",
    "    for block in data:\n",
    "        pp_documents.append(preprocess(block['reviewText'], train))\n",
    "        labels.append(int(block['overall']))\n",
    "    \n",
    "    return pp_documents, np.array(labels)"
   ]
  },
  {
   "source": [
    "- **Tạo histogram vector**\n",
    "    - Khởi tạo một vector toàn số 0 với số chiều bằng độ dài của bộ từ điển. `numpy` có phương thức `np.zeros(shape)` hỗ trợ công việc này.\n",
    "    - Đếm số lần xuất hiện của mỗi từ thuộc bộ từ điển trong đoạn văn hiện tại rồi cập nhật phần tử vector tại vị trí đó. Vì kết quả sau khi tiền xử lí văn bản là một `list` các từ, để thực hiện đếm ta chỉ cần gọi `list.count()` với tham số đầu vào là phần từ cần đếm. Các từ 'unk' sẽ không được đếm.\n",
    "    - Áp dụng công thức a / (1.T @ a) để tạo vector tần suất từ.\n",
    "        - Tạo vector 1 bằng `np.ones(shape)`.\n",
    "        - Dùng toán tử `@` để thực hiện phép nhân.\n",
    "        - Có thể dùng toán từ `/` hoặc dùng `np.divide` để tính toán phép chia ma trận."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_vector(document):\n",
    "    # Khởi tạo vector 0\n",
    "    word_count_vector = np.zeros(len(vocab))\n",
    "\n",
    "    # Đếm số lần xuất hiện của mỗi từ\n",
    "    for i, v in enumerate(vocab):\n",
    "        word_count_vector[i] = document.count(v)\n",
    "    \n",
    "    # Áp dụng công thức để tạo vector tần suất từ\n",
    "    return np.divide(word_count_vector, np.ones(len(vocab)).T @ word_count_vector)"
   ]
  },
  {
   "source": [
    "- **Tạo ma trận histogram (document-term matrix)**\n",
    "    - Mỗi văn bản qua hàm `histogram_vector` sẽ tạo thành 1 histogram vector. Xếp các vector này theo hàng ta được ma trận histogram\n",
    "    - Để xếp các vector theo dòng, dùng hàm `np.vstack()` rồi truyền vào đó `list` các mảng muốn xếp."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_term_matrix(documents):\n",
    "    # Xếp các histogram vector thành ma trận\n",
    "    return np.vstack([histogram_vector(doc) for doc in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng mô hình hồi quy tuyến tính dùng bình phương tối tiểu"
   ]
  },
  {
   "source": [
    "- **Xử lí nhãn văn bản**\n",
    "    - Do em chọn mô hình M2 nên cần dự đoán nhãn theo trường overall từ 1-5. Với mô hình này, kết quả của hồi quy tuyến tính một vector `y` 5 chiều, mỗi phần tử tại `i` của vector là xác suất để `overall = i + 1`.\n",
    "    - Nhãn văn bản có xác suất là 100% nên tại nếu `overall = i` thì phần tử có index `i - 1` sẽ là `1`, còn lại là `0` vì sẽ xác suất overall rơi vào đó là 0%. VD: `overall = 5` thì `y = [0 0 0 0 1]`.\n",
    "    - Để tạo được vector này, ta dùng `np.identity(5)` để tạo ma trận đơn vị 5x5. Tại __dòng__ thứ `i` của ma trận này, phần tử ở __cột__ thứ i là 1.\n",
    "    - Tham số truyền vào là ma trận cột các nhãn văn bản nên ta xử lí tương tự cho từng nhãn rồi `np.vstack` chúng theo dòng để có kết quả mong muốn. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYs(ys):\n",
    "    return np.vstack([np.identity(5)[rate - 1] for rate in ys])"
   ]
  },
  {
   "source": [
    "- **Lấy các tham số A, b cho hàm Linear Regression**\n",
    "    - Đối với ma trận A: Ghép ma trận cột 1 với ma trận tần suất từ `xs`. Dùng `np.concatenate` trên `axis=1` để ghép.\n",
    "    - Đối với ma trận b: Xử lí nhãn văn bản `ys` bằng hàm `getYs()` đã cài đặt ở trên."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(xs, ys):\n",
    "    A = np.concatenate((np.ones((len(xs), 1)), xs), axis=1)\n",
    "    b = getYs(ys)\n",
    "    return A, b"
   ]
  },
  {
   "source": [
    "- **Xây dựng mô hình bằng phương pháp hồi quy tuyến tính**\n",
    "    - Áp dụng công thức x_hat = (A.T @ A) ^ -1 @ A.T @ b, trong đó: giả nghịch đảo(A) = (A.T @ A) ^ -1 @ A.T\n",
    "    - Giả nghịch đảo có thể được tính bằng `np.linalg.pinv()` và toán tử `@` để thực hiện phép nhân."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(A, b):\n",
    "    return np.linalg.pinv(A) @ b"
   ]
  },
  {
   "source": [
    "- **Phân loại (dự đoán số điểm) tập dữ liệu bằng mô hình dựng được**\n",
    "    - Áp dụng `Ax = y`, ta thu được tập `y`. \n",
    "    - Như đã nói ở trên, vector nhãn được thể hiện dưới dạng xác suất rơi vào từng loại điểm. Vậy ta phải chuyển `y` thu được về vector xác suất thông qua hàm `scipy.special.softmax()`.\n",
    "    - Index có xác suất cao nhất là nhãn được dự đoán của văn bản. Dùng `np.argmax()` để lấy ra index của phần tử lớn nhất.\n",
    "    - Mảng nhãn văn bản có index từ 0-4 nhưng số điểm của người dùng chấm thuộc khoảng 1-5 bên sau khi lấy ra index của phần tử lớn nhất ta phải cộng thêm 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(A_test, model):\n",
    "    return np.argmax(scipy.special.softmax(A_test @ model, axis=1), axis=1) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng độ chính xác để đánh giá mô hình"
   ]
  },
  {
   "source": [
    "- **Tính độ chính xác qua nhãn phân loại được và nhãn thực**\n",
    "    - Độ chính xác được tính theo công thức: Số nhãn đúng / Tổng số nhãn\n",
    "    - Để đếm số nhãn đúng, tạo một ma trận tạm với điều kiện bằng với nhãn thực sự gồm các giá trị `True/False`. Sau đó dùng `np.count_nonzero()` để đếm số giá trị `True` trong đó."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, labels_test):\n",
    "    return np.count_nonzero(predict == labels_test) / len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "source": [
    "### Nhận các tham số"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE this part: read data path\n",
    "train_set_path, valid_set_path, random_number = input().split()"
   ]
  },
  {
   "source": [
    "### Đọc và tiền xử lí bộ train và test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_train, labels_train = read(train_set_path, True)\n",
    "docs_test, labels_test = read(valid_set_path, False)"
   ]
  },
  {
   "source": [
    "### In ra kết quả tiền xử lí thứ `random_number` trong bộ valid/test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(docs_test[int(random_number)])"
   ]
  },
  {
   "source": [
    "### Tạo các ma trận đầu vào cho việc dựng mô hình và kiểm mô hình"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = document_term_matrix(docs_train)\n",
    "A_train, b_train = getParameters(matrix_train, labels_train)\n",
    "\n",
    "matrix_test = document_term_matrix(docs_test)\n",
    "A_test, b_test = getParameters(matrix_test, labels_test)"
   ]
  },
  {
   "source": [
    "### Xây dựng mô hình"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(A_train, b_train)"
   ]
  },
  {
   "source": [
    "### Từ model đã có, phân loại văn bản trong tập train/valid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = classify(A_test, model)"
   ]
  },
  {
   "source": [
    "### Tính độ chính xác"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(predict, labels_test)"
   ]
  },
  {
   "source": [
    "### In ra màn hình loại mô hình (M1/M2) và độ chính xác của nó"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('M2 - ' + str(acc))"
   ]
  }
 ]
}